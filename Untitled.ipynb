{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0fd6f1-4116-4606-a2bd-ff992860a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Setting the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Setting the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Setting the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Setting the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. Configuring a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57c19298",
   "metadata": {},
   "source": [
    "# **Neural Network Models**\n",
    "1. Regular Neural Net\n",
    "2. CNN\n",
    "3. Transfer Learning with ResNet50\n",
    "4. Autoencoder\n",
    "5. Mobilenet\n",
    "6. Inceptionnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525b2a9-bc6c-404f-b935-74f5e40f0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8752ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data science imports\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "import sklearn.model_selection \n",
    "import sklearn.linear_model\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.discriminant_analysis\n",
    "import sklearn.metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow imports\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, MaxPooling2D, Flatten, Input\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e132813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Imports\n",
    "import visualkeras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from PIL import ImageFont\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2955fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compute metrics\n",
    "\n",
    "def get_f1(y_true, y_pred): \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "\n",
    "    true_negatives=int(len(y_pred)) - ((int(possible_positives) + int(predicted_positives))-int(true_positives))\n",
    "    return(f1_val)\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "\n",
    "    true_negatives=int(len(y_pred)) - ((int(possible_positives) + int(predicted_positives))-int(true_positives))\n",
    "    accuracy = (tf.cast(true_positives, tf.float32) + tf.cast(true_negatives, tf.float32)) / tf.cast(len(y_pred), tf.float32)\n",
    "    return(accuracy)\n",
    "\n",
    "def prec(y_true, y_pred): \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "\n",
    "    true_negatives=int(len(y_pred)) - ((int(possible_positives) + int(predicted_positives))-int(true_positives))\n",
    "    return(precision)\n",
    "\n",
    "def rec(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "\n",
    "    true_negatives=int(len(y_pred)) - ((int(possible_positives) + int(predicted_positives))-int(true_positives))\n",
    "    return(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class to train sklearn gridsearchcv models & report metrics\n",
    "class gridsearchcv_model:\n",
    "    def __init__(self, model, X_train, Y_train, X_val, Y_val, parameter_matrix={}, is_classification=False, cv=4):\n",
    "        self.is_classification = is_classification\n",
    "        self.train_model(model, X_train, Y_train, X_val, Y_val, parameter_matrix, cv)\n",
    "        \n",
    "    # Trains model using a training set and predicts a validation set\n",
    "    def train_model(self, model, X_train, Y_train, X_val, Y_val, parameter_matrix={}, cv=4):\n",
    "        ml_model = sklearn.model_selection.GridSearchCV(model, parameter_matrix, cv=cv, scoring='f1')\n",
    "     \n",
    "        ml_model.fit(X_train, Y_train)\n",
    "        \n",
    "        self.model = ml_model.best_estimator_\n",
    "        self.name = re.compile(\"(.*?)\\s*\\(\").match(str(self.model)).group(1)\n",
    "        \n",
    "        self.train = {'name': 'train'}\n",
    "        self.val = {'name': 'val'}\n",
    "        \n",
    "        self.calculate_error(self.train, X_train, Y_train, self.train['name'])\n",
    "        self.calculate_error(self.val, X_val, Y_val, self.val['name'])\n",
    "        \n",
    "        return ml_model\n",
    "    \n",
    "    def calculate_error(self, var, X_set, Y_set, name):\n",
    "        var['name'] = name\n",
    "        var['predictions'] = self.model.predict(X_set)\n",
    "        \n",
    "        var['f1_score'] = sklearn.metrics.f1_score(Y_set, var['predictions'])\n",
    "        var['accuracy'] = sklearn.metrics.accuracy_score(Y_set, var['predictions'])\n",
    "        var['precision'] = sklearn.metrics.precision_score(Y_set, var['predictions'])\n",
    "        var['recall'] = sklearn.metrics.recall_score(Y_set, var['predictions'])\n",
    "        \n",
    "        self.print_error(var)\n",
    "        \n",
    "    # Prints error metrics\n",
    "    def print_error(self, var):\n",
    "        print(self.name + ' ('+ var['name'] + ')')\n",
    "        \n",
    "        print(\"Accuracy: %0.4f\" % var['accuracy'])\n",
    "        print(\"f1_score: %0.4f\" % var['f1_score'])\n",
    "        print(\"precision: %0.4f\" % var['precision'])\n",
    "        print(\"recall: %0.4f\" % var['recall'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f013638f",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data into dataframes\n",
    "df_train_original = pd.read_pickle (\"data/epoched_train.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5593ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column 'pid' which is the patient ID 1 through 9\n",
    "df_train_original['pid'] = [int(df_train_original['patient_id'][x][2]) for x in range(len(df_train_original))]\n",
    "\n",
    "# Create column 'trial_id' which is the trial 1 through 3\n",
    "df_train_original['trial_id'] = [int(df_train_original['patient_id'][x][-2]) for x in range(len(df_train_original))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the dataset into training, validation and test set \n",
    "\n",
    "df_train = df_train_original[df_train_original['trial_id']!=3]\n",
    "df_train = df_train_original.reindex(np.random.permutation(df_train_original.index)).reset_index(drop=True)\n",
    "\n",
    "df_val_test = df_train_original[df_train_original['trial_id']==3]\n",
    "df_val_test = df_val_test.reindex(np.random.permutation(df_val_test.index)).reset_index(drop=True)\n",
    "\n",
    "df_val = df_val_test[0:int(len(df_val_test)/2)]\n",
    "df_test = df_val_test[int(len(df_val_test)/2):len(df_val_test)]\n",
    "df_train_val = df_train.append(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca034efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment training data by adding Gaussian noise (to avoid overfitting)\n",
    "for _ in range(1): \n",
    "    df_train_augment = df_train.copy()\n",
    "    for x in ['C3', 'Cz', 'C4', 'EOG:ch01', 'EOG:ch02','EOG:ch03']:\n",
    "        df_train_augment[x] += np.random.normal(0,1)\n",
    "\n",
    "    df_train = pd.concat([df_train, df_train_augment])\n",
    "\n",
    "\n",
    "for _ in range(1): \n",
    "    df_train_val_augment = df_train_val.copy()\n",
    "    for x in ['C3', 'Cz', 'C4', 'EOG:ch01', 'EOG:ch02','EOG:ch03']:\n",
    "        df_train_val_augment[x] += np.random.normal(0,1)\n",
    "\n",
    "    df_train_val = pd.concat([df_train, df_train_val_augment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4371071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training across all subjects\n",
    "y_train = df_train[\"event_type\"].values.astype(float)\n",
    "y_val = df_val[\"event_type\"].values.astype(float)\n",
    "y_train_val = df_train_val[\"event_type\"].values.astype(float)\n",
    "y_test = df_test[\"event_type\"].values.astype(float)\n",
    "\n",
    "X_train = df_train.drop([\"patient_id\", \"start_time\", \"event_type\", \"pid\", \"trial_id\"], axis=1)\n",
    "X_val = df_val.drop([\"patient_id\", \"start_time\", \"event_type\", \"pid\", \"trial_id\"], axis=1)\n",
    "X_train_val = df_train_val.drop([\"patient_id\", \"start_time\", \"event_type\", \"pid\", \"trial_id\"], axis=1)\n",
    "X_test = df_test.drop([\"patient_id\", \"start_time\", \"event_type\",\"pid\", \"trial_id\"], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8dc5418",
   "metadata": {},
   "source": [
    "## **1. Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the data for sklearn & neural net models\n",
    "x_train_nn = np.array(X_train.apply(lambda x:np.concatenate(x), axis=1).values.tolist())\n",
    "x_val_nn = np.array(X_val.apply(lambda x:np.concatenate(x), axis=1).values.tolist())\n",
    "x_train_val_nn = np.array(X_train_val.apply(lambda x:np.concatenate(x), axis=1).values.tolist())\n",
    "x_test_nn = np.array(X_test.apply(lambda x:np.concatenate(x), axis=1).values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular neural net\n",
    "neural_network = keras.Sequential([Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "                                   Dropout(0.2),\n",
    "                                   Dense(32, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "                                   Dropout(0.2),\n",
    "                                   Dense(1, activation=\"sigmoid\")])\n",
    "\n",
    "neural_network.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=[get_f1, acc, prec, rec])\n",
    "\n",
    "history_nn = neural_network.fit(x_train_val_nn, y_train_val, epochs=50, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e72bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "neural_network.evaluate(x_test_nn, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21f89c29",
   "metadata": {},
   "source": [
    "## **2. CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8da08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the data for CNN models\n",
    "x_train_cnn = np.array(X_train.apply(lambda x:np.stack(x, axis=-1), axis=1).values.tolist())\n",
    "x_train_cnn = x_train_cnn.reshape(list(x_train_cnn.shape)+[1])\n",
    "\n",
    "x_train_val_cnn = np.array(X_train_val.apply(lambda x:np.stack(x, axis=-1), axis=1).values.tolist())\n",
    "x_train_val_cnn = x_train_val_cnn.reshape(list(x_train_val_cnn.shape)+[1])\n",
    "\n",
    "x_test_cnn = np.array(X_val.apply(lambda x:np.stack(x, axis=-1), axis=1).values.tolist())\n",
    "x_test_cnn = x_test_cnn.reshape(list(x_test_cnn.shape)+[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.Sequential([Conv2D(32, (3, 3), activation=\"relu\", input_shape=(1000, 6, 1)),\n",
    "                        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "                        Flatten(),\n",
    "                        Dense(256, activation=\"relu\"),\n",
    "                        Dropout(0.2),\n",
    "                        Dense(128, activation=\"relu\"),\n",
    "                        Dense(1, activation=\"sigmoid\")])\n",
    "\n",
    "cnn.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=[get_f1, acc, prec, rec])\n",
    "\n",
    "history_cnn = cnn.fit(x_train_val_cnn, y_train_val, epochs=50, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc512aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "cnn.evaluate(x_test_cnn, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84c746fd",
   "metadata": {},
   "source": [
    "## **3. Resnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for transfer learning models\n",
    "x_train_transfer = x_train_cnn.reshape((len(x_train_cnn), 50, 40, 3))\n",
    "x_train_val_transfer = x_train_val_cnn.reshape((len(x_train_val_cnn), 50, 40, 3))\n",
    "x_test_transfer = x_test_cnn.reshape((len(x_test_cnn), 50, 40, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_weights_path = 'archive/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "transfer_network = keras.Sequential([ResNet50(include_top=False, weights=resnet_weights_path, input_shape=(50,40,3)),\n",
    "                                     Flatten(),\n",
    "                                     Dense(1, activation=\"sigmoid\")])\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "transfer_network.layers[0].trainable = False\n",
    "\n",
    "transfer_network.compile(optimizer=opt, loss='binary_crossentropy', metrics=[get_f1, acc, prec, rec])\n",
    "\n",
    "history_rn = transfer_network.fit(x_train_val_transfer, y_train_val, epochs=250, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86273fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transfer_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52610c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "transfer_network.evaluate(x_test_transfer, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0b4bde2",
   "metadata": {},
   "source": [
    "## **4. Autoencoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80600a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for autoencoder\n",
    "latent_factors = 25\n",
    "\n",
    "x_train_ae = x_train_nn.reshape(-1,latent_factors)\n",
    "x_val_ae = x_val_nn.reshape(-1,latent_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b795177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "autoencoder = keras.Sequential([Dense(latent_factors, activation=\"relu\")])\n",
    "\n",
    "autoencoder.compile(optimizer=Adam(lr=0.001), loss=keras.losses.MeanSquaredError())\n",
    "\n",
    "history_ae = autoencoder.fit(x_train_ae, x_train_ae, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat data back to original\n",
    "ae_preds_train = autoencoder.predict(x_train_ae).reshape(-1, 6000)\n",
    "ae_preds_val = autoencoder.predict(x_val_ae).reshape(-1, 6000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cd75e2b",
   "metadata": {},
   "source": [
    "## **5. MobileNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_nn.shape)\n",
    "print(x_val_nn.shape)\n",
    "print(x_train_val_nn.shape)\n",
    "print(x_test_nn.shape)\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739fb98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mn = x_train_nn.reshape([7360,75,80,1])\n",
    "x_train_val_mn = x_train_val_nn.reshape([11760,75,80,1])    \n",
    "x_val_mn = x_val_nn.reshape([720,75,80,1])\n",
    "x_test_mn = x_test_nn.reshape([720,75,80,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = keras.applications.mobilenet.MobileNet(input_shape=(75, 80, 1),\n",
    "    weights=None,\n",
    "    classes=1\n",
    "    )\n",
    "\n",
    "mobile.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=[get_f1, acc, prec, rec])\n",
    "history_mn = mobile.fit(x_train_val_mn, y_train_val, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3082cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "mobile.evaluate(x_test_mn, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9668537",
   "metadata": {},
   "source": [
    "## **6. Inceptionnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = keras.applications.InceptionV3(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(75, 80, 1),\n",
    "    pooling=None,\n",
    "    classes=1,\n",
    "    classifier_activation=\"softmax\"\n",
    "    )\n",
    "\n",
    "inception.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=[get_f1, acc, prec, rec])\n",
    "history_in = inception.fit(x_train_val_mn, y_train_val, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.summmary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
